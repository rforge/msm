%%\VignetteIndexEntry{User guide to msm with worked examples}
%\VignettePackage{msm}
\documentclass{article}

%% Need to modify Sweave.sty to pass pdftex option to graphicx.
\usepackage{Sweave-local}
\usepackage{times}
\usepackage{url}
\addtolength{\textwidth}{2cm}

\newcommand{\Exp}{\mathop{\mathrm{Exp}}}
\newcommand{\etal}{{\textit{et al.}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}


%% version <- 1.3

<<echo=FALSE>>=
version <- gsub("Version: +", "",
               packageDescription("msm", lib.loc="../../..")$Version)
@

\title{Multi-state modelling with R: the {\tt msm} package \vskip 0.2in
  \large{Version %
<<echo=FALSE,results=tex>>=
cat(version)
@
\vskip 0.1in
<<echo=FALSE,results=tex>>=
cat(format(Sys.time(), "%d %B, %Y"))
@
}}
\author{Christopher Jackson\\MRC Biostatistics Unit\\Cambridge, U.K.\\ \texttt{chris.jackson@mrc-bsu.cam.ac.uk}}
\date{}
%% label with date when Rnw is compiled, not when tex is compiled. should be release date of package

\bibliographystyle{unsrt}

\begin{document}

\maketitle

\begin{abstract}

  The multi-state Markov model is a useful way of describing a process
  in which an individual moves through a series of states in
  continuous time.  The \Rpackage{msm} package for R allows a general
  multi-state model to be fitted to longitudinal data. Data often
  consist of observations of the process at arbitrary times, so that
  the exact times when the state changes are unobserved.  For example,
  the progression of chronic diseases is often described by stages of
  severity, and the state of the patient may only be known at doctor
  or hospital visits.  Features of \Rpackage{msm} include the ability
  to model transition rates and hidden Markov output models in terms
  of covariates, and the ability to model data with a variety of
  observation schemes, including censored states.

  Hidden Markov models, in which the true path through states is only
  observed through some error-prone marker, can also be fitted.  The
  observation is generated, conditionally on the underlying states,
  via some distribution.  An example is a screening misclassification
  model in which states are observed with error.  More generally,
  hidden Markov models can have a continuous response, with some
  arbitrary distribution, conditionally on the underlying state.

  This manual introduces the theory behind multi-state Markov and
  hidden Markov models, and gives a tutorial in the typical use of the
  \Rpackage{msm} package, illustrated by some typical applications to
  modelling chronic diseases.

  Much of the material in this manual is published, in a more concise
  form, in Journal of Statistical Software (2011) 38(8):1-29,
  \url{http://www.jstatsoft.org/v38/i08/}

\end{abstract}

\section{Multi-state models}
\label{sec:multistate}

\subsection{Introduction}
\label{sec:intro}


Figure~\ref{fig:multi} illustrates a multi-state model in continuous
time. Its four states are labelled {\bf 1, 2, 3, 4}.  At a time $t$
the individual is in state $S(t)$.  The arrows show which transitions
are possible between states. The next state to which the individual
moves, and the time of the change, are governed by a set of {\em
  transition intensities} $q_{rs}(t, z(t))$ for each pair of states
$r$ and $s$.  The intensities may also depend on the time of the
process $t$, or more generally a set of individual-specific or
time-varying explanatory variables $z(t)$.  The intensity represents
the instantaneous risk of moving from state $r$ to state $s$:
\begin{equation}
  \label{eq:multi:intensity}
  q_{rs}(t, z(t))  =  \lim_{\delta t \rightarrow 0} P (S(t+\delta t) = s | S(t) = r) / \delta t
\end{equation}
The intensities form a matrix $Q$ whose rows sum to zero, so that the
diagonal entries are defined by $q_{rr} = - \sum_{s \neq r} q_{rs}$.

To fit a multi-state model to data, we estimate this transition
intensity matrix.  We concentrate on {\em Markov} models here. The
Markov assumption is that future evolution only depends on the current
state.  That is, $q_{rs}(t, z(t), \mathcal{F}_t)$ is independent of
$\mathcal{F}_t$, the observation history $\mathcal{F}_t$ of the
process up to the time preceding $t$.  See, for example, Cox and
Miller\cite{cox:miller} for a thorough
introduction to the theory of continuous-time Markov chains.

\begin{figure}[p]
  \begin{center}
    \scalebox{0.4}{\includegraphics{figures/multistate}}
    \[
    Q = \left(
      \begin{array}{llll}
        q_{11} & q_{12} & q_{13} & q_{14}\\
        q_{21} & q_{22} & q_{23} & q_{24}\\
        q_{31} & q_{32} & q_{33} & q_{34}\\
        q_{41} & q_{42} & q_{43} & q_{44}\\
      \end{array}
    \right )
    \]
    \caption{\label{fig:multi}General multi-state model.}
  \end{center}
\end{figure}

In a time-homogeneous continuous-time Markov model, a single period of occupancy (or
\emph{sojourn time}) in state $r$ has an exponential distribution,
with rate given by $-q_{rr}$, (or
mean $-1 / q_{rr}$).  The remaining elements of the $r$th row of $Q$
are \emph{proportional to} the probabilities governing the next state
after $r$ to which the individual makes a transition.  The probability
that the individual's next move from state $r$ is to state $s$ is
$-q_{rs} / q_{rr}$.


\subsection{Disease progression models}

The development of the \Rpackage{msm} package was motivated by
applications to disease modelling.  Many chronic diseases have a
natural interpretation in terms of staged progression. Multi-state
Markov models in continuous time are often used to model the course of
diseases. A commonly-used model is illustrated in
Figure \ref{fig:disease}.  This represents a series of successively
more severe disease stages, and an `absorbing' state, often death.
The patient may advance into or recover from adjacent disease stages,
or die at any disease stage.  Observations of the state $S_i(t)$ are
made on a number of individuals $i$ at arbitrary times $t$, which may
vary between individuals.  The stages of disease may be modelled as a
homogeneous continuous-time Markov process, with a transition matrix
$Q$, pictured below Figure \ref{fig:disease}.

A commonly-used model is the \emph{illness-death} model, with three
states representing health, illness and death
(Figure \ref{fig:multi:illdeath}).  Transitions are permitted from
health to illness, illness to death and health to death.  Recovery
from illness to health is sometimes also considered.

A wide range of medical situations have been modelled using
multi-state methods, for example, screening for abdominal aortic
aneurysms (Jackson \etal\cite{jackson:sharples:2003}),
problems following lung transplantation (Jackson and
Sharples\cite{jackson:sharples:2002}), problems following heart
transplantation (Sharples\cite{sharp:gibbs}, Klotz and
Sharples\cite{klotz:est}), hepatic cancer (Kay\cite{kay:mark}), HIV
infection and AIDS (Longini \etal\cite{long1}, Satten and
Longini\cite{sattlong}, Guihenneuc-Jouyaux \etal\cite{rich},
Gentleman \etal\cite{gentlaw}), diabetic complications
(Marshall and Jones\cite{retino2}, Andersen\cite{andersen88}), breast
cancer screening (Duffy and Chen\cite{duffy95}, Chen \emph{et
  al.}\cite{duffy96}), cervical cancer screening (Kirby and
Spiegelhalter\cite{kirby:spiegelhalter}) and liver cirrhosis (Andersen
\etal\cite{ander:proth}).  Many of these references also
describe the mathematical theory, which will be reviewed in the
following sections.


\begin{figure}[p]
  \centering
  \vskip 1cm
  \scalebox{1.0}{\includegraphics{figures/general}}
    \[
    Q = \left(
      \begin{array}{llllll}
        q_{11} & q_{12} & 0 & 0 & \ldots & q_{1n}\\
        q_{21} & q_{22} & q_{23} & 0 & \ldots & q_{2n}\\
        0 & q_{32} & q_{33} & q_{34} & \ddots & q_{3n}\\
        0 & 0 & q_{43} & q_{44} & \ddots & q_{4n}\\
        \vdots & \vdots & \ddots & \ddots & \ddots & \vdots\\
        0 & 0 & 0 & 0 & \ldots & 0\\
      \end{array}
    \right )
    \]
  \caption{\label{fig:disease}General model for disease progression.}
  \end{figure}

\begin{figure}[p]
  \begin{center}
    \scalebox{0.4}{\includegraphics{figures/illdeath}}
    \caption{Illness-death model.}
    \label{fig:multi:illdeath}
  \end{center}
\end{figure}

\subsection{Arbitrary observation times}
\label{sec:arbitr-observ-times}

Longitudinal data from monitoring disease progression are often
incomplete in some way.  Usually patients are seen at intermittent
follow-up visits, at which monitoring information is collected, but
information from the periods between visits is not available.  Often
the exact time of disease onset is unknown. Thus, the changes of state
in a multi-state model usually occur at unknown times.  Also a subject
may only be followed up for a portion of their disease history.  A
fixed observation schedule may be specified in advance, but in
practice times of visits may vary due to patient and hospital
pressures. The states of disease progression models often include
death. Death times are commonly recorded to within a day.  Also
observations may be censored.  For example, at the end of a study, an
individual may be known only to be alive, and in an unknown state.

A typical sampling situation is illustrated in
Figure \ref{fig:multi:sampling}. The individual is observed at four
occasions through 10 months. The final occasion is the death date
which is recorded to within a day. The only other information
available is the occupation of states 2, 2, and 1 at respective times
1.5, 3.5 and 5. The times of movement between states and the state
occupancy in between the observation times are unknown.  Although the
patient was in state 3 between 7 and 9 months this was not observed at
all.

\paragraph{Informative sampling times}
To fit a model to longitudinal data with arbitrary sampling times we
must consider the reasons why observations were made at the given
times.  This is analogous to the problem of missing data, where the
fact that a particular observation is missing may implicitly give
information about the value of that observation. Possible observation
schemes include:
\begin{itemize}
\item {\em fixed}. Each patient is observed at fixed intervals
  specified in advance.
\item {\em random}. The sampling times vary randomly, independently
  of the current state of the disease.
\item {\em doctor's care}. More severely ill patients are monitored
  more closely. The next sampling time is chosen on the basis of the
  current disease state.
\item patient {\em self-selection}. A patient may decide to visit the
  doctor on occasions when they are in a poor condition.
\end{itemize}
Gr\"uger \etal \cite{gruger:valid} discussed conditions under
which sampling times are \emph{informative}. If a multi-state model is
fitted, ignoring the information available in the sampling times, then
inference may be biased.  Mathematically, because the sampling
times are often themselves random, they should be modelled along with
the observation process $X_t$. However the ideal situation is where
the joint likelihood for the times and the process is proportional to
the likelihood obtained if the sampling times were fixed in advance.
Then the parameters of the process can be estimated independently of
the parameters of the sampling scheme.

In particular, they showed that fixed, random and doctor's care
observation policies are not informative, whereas patient
self-selection is informative.   Note that \Rpackage{msm} does not
deal with informative sampling times. See, e.g. \cite{sweeting:inform:msm}
for some methods in this case, which require specialised programming.

\begin{figure}[p]
  \begin{center}
    \scalebox{0.6}{\rotatebox{270}{\includegraphics{figures/sampling}}}
    \caption{Evolution of a multi-state model. The process is observed
      on four occasions.}
    \label{fig:multi:sampling}
  \end{center}
\end{figure}




\subsection{Likelihood for the multi-state model}
\label{sec:multi:likelihood}

Kalbfleisch and Lawless\cite{kalbfleisch:lawless} and later
Kay \cite{kay:mark} described a general method for evaluating the
likelihood for a general multi-state model in continuous time,
applicable to any form of transition matrix. The only available
information is the observed state at a set of times, as in
Figure \ref{fig:multi:sampling}.  The sampling times are assumed to be
non-informative.

\paragraph{Transition probability matrix}
The likelihood is calculated from the \emph{transition probability matrix}
$P(t)$.  For a time-homogeneous process, the $(r,s)$ entry of $P(t)$,
$p_{rs}(t)$, is the probability of being in state $s$ at a time $t+u$
in the future, given the state at time $u$ is $r$.  It does not say
anything about the time of transition from $r$ to $s$, indeed the
process may have entered other states between times $u$ and $t+u$.
$P(t)$ can be calculated by taking the matrix exponential of the
scaled transition intensity matrix (see, for example, Cox and
Miller \cite{cox:miller}).
\begin{equation}
  \label{eq:exptq}
  P(t) = \Exp(tQ)
\end{equation}

The matrix exponential $\Exp$ is different from a scalar exponential.
The exponential of a matrix is defined by the same "power series"
$\Exp(X) = 1 + X^2/2! + X^3/3! + ...$ as the scalar exponential,
except that each term $X^k$ in the series is defined by matrix products,
not element-wise scalar multiplication.  It is notoriously difficult
to calculate reliably, as discussed by Moler and van Loan \cite{matrixexp}.
For simpler models, it is feasible to calculate an analytic expression
for each element of $P(t)$ in terms of $Q$.  This is generally faster
and avoids the potential numerical instability of calculating the
matrix exponential.  Symbolic algebra sofware, such as Mathematica,
can be helpful for obtaining these expressions.  For example, the
three-state illness-death model with no recovery has a transition
intensity matrix of
\[
Q = \left(
  \begin{array}{llllll}
    -(q_{12} + q_{13}) & q_{12} & q_{13}\\
    0 & - q_{23} & q_{23}\\
    0 & 0 & 0\\
  \end{array}
\right )
\]
The corresponding time $t$ transition probabilities are
\begin{eqnarray*}
  p_{11}(t) & = & e^{-(q_{12} + q_{13})t}\\
  p_{12}(t) & = &
\left\{
\begin{array}{ll}
\frac{ q_{12}(-1 + e^{(q_{12}+q_{13}-q_{23})t})e^{-(q_{12}+q_{13})t} } { (q_{12} + q_{13} - q_{23}) } & (q_{12} + q_{13} \neq q_{23})\\
q_{12}te^{(-(q_{12} + q_{13})t} &  (q_{12} + q_{13} = q_{23})
\end{array}
\right.
\\
  p_{13}(t) & = &
\left\{
\begin{array}{ll}
\frac{1 + (-q_{13} + q_{23})e^{-(q_{12}+q_{13})t}} {q_{12} + q_{13} - q_{23}} - \frac { q_{12}e^{-q_{23}t}} {q_{12} + q_{13} - q_{23} } & (q_{12} + q_{13} \neq q_{23})\\
 (-1 + e^{(q_{12} + q_{13})t} - q_{12}t)e^{-(q_{12} + q_{13})t} & (q_{12} + q_{13} = q_{23})
\end{array}
\right.
\\
  p_{21}(t) & = & 0\\
  p_{22}(t) & = & e^{-q_{23}t}\\
  p_{23}(t) & = & 1 - e^{-q_{23}t}\\
  p_{31}(t) & = & 0\\
  p_{32}(t) & = & 0\\
  p_{33}(t) & = & 1\\
\end{eqnarray*}
The \Rpackage{msm} package calculates $P(t)$ analytically for selected
2, 3, 4 and 5-state models, illustrated in
Figures \ref{fig:anp2}--\ref{fig:anp5}.  For other models, which can have any transition
structure on any number of states in principle, $P(t)$ is
determined from the matrix exponential.  This is calculated using eigensystem
decomposition (if eigenvalues are distinct) or a method based on
Pad\'e approximants with scaling and squaring \cite{matrixexp} (if
there are repeated eigenvalues). Notice that the states are not
labelled in these figures.  Each graph can correspond to several
different $Q$ matrices, depending on how the states are labelled.  For
example, Figure 1 a) illustrates the model defined by either \( Q =
\left(
  \begin{array}{ll}
    - q_{12} & q_{12} \\
    0 & 0
\end{array}
\right)
\)
or
\(
Q = \left( \begin{array}{ll}
0 & 0\\
q_{21} & - q_{21}
\end{array}
\right)
\).

\begin{figure}
\begin{center}
a) \includegraphics[width=3cm]{figures/p2q1} \hskip 3cm
b) \includegraphics[width=3cm]{figures/p2q12}
\end{center}
\caption{\label{fig:anp2}Two-state models fitted using analytic $P(t)$ matrices in \Rpackage{msm}. Implemented for all permutations of state labels 1, 2.}
\end{figure}
\begin{figure}
\begin{center}
a) \includegraphics[width=3cm]{figures/p3q12} \hskip 3cm
b) \includegraphics[width=5cm]{figures/p3q14} \vskip 1cm
c) \includegraphics[width=3cm]{figures/p3q16}\hskip 3cm
d) \includegraphics[width=3cm]{figures/p3q124}\vskip 1cm
e) \includegraphics[width=3cm]{figures/p3q135}\hskip 3cm
f) \includegraphics[width=3cm]{figures/p3q1246}
\end{center}
\caption{\label{fig:anp3}Three-state models fitted using analytic $P(t)$ matrices in \Rpackage{msm}. Implemented for all permutations of state labels 1, 2, 3.}
\end{figure}
\begin{figure}
\begin{center}
a) \includegraphics[width=7cm]{figures/p4q159} \vskip 1cm
b) \includegraphics[width=7cm]{figures/p4q13569}
\end{center}
\caption{\label{fig:anp4}Four-state models fitted using analytic $P(t)$ matrices in \Rpackage{msm}. Implemented for all permutations of state labels 1, 2, 3, 4.}
\end{figure}
\begin{figure}
\begin{center}
a) \includegraphics[width=9cm]{figures/p5q1_6_11_16}\vskip 1cm
b) \includegraphics[width=9cm]{figures/p5q1_4_6_8_11_12_16}\vskip 1cm
c) \includegraphics[width=5cm]{figures/p5q1_6_7_11_12}
\end{center}
\caption{\label{fig:anp5}Five-state models fitted using analytic $P(t)$ matrices in \Rpackage{msm}. Implemented for all permutations of state labels 1, 2, 3, 4, 5.}
\end{figure}

\paragraph{Likelihood for intermittently-observed processes}
Suppose $i$ indexes $M$ individuals.  The data for individual $i$
consist of a series of times $(t_{i1}, \ldots, t_{in_i})$ and
corresponding states $(S(t_{i1}), \ldots, S(t_{in_i}))$.  Consider a
general multi state model, with a pair of successive observed disease
states $S(t_j), S(t_{j+1})$ at times $t_j, t_{j+1}$. The contribution
to the likelihood from this pair of states is

\begin{equation}
  \label{eq:multi:lik:contrib}
  L_{i, j} =  p_{S(t_j)S(t_{j+1})}(t_{j+1} - t_j)
\end{equation}
This is the entry of the transition matrix $P(t)$ at the $S(t_j)$th
row and $S(t_{j+1})$th column, evaluated at $t = t_{j+1} - t_j$.

The full likelihood $L(Q)$ is the product of all such terms $L_{i,j}$
over all individuals and all transitions. It depends on the unknown
transition matrix $Q$, which was used to determine $P(t)$.

\paragraph{Exactly-observed death times}
In observational studies of chronic diseases, it is common that the
time of death is known, but the state on the previous instant before
death is unknown. If $S(t_{j+1}) = D $ is such a death state, then the
contribution to the likelihood is summed over the unknown state $m$ on
the instant before death:

\begin{equation}
  \label{eq:multi:lik:death}
  L_{i, j} =  \sum_{m \neq D} p_{S(t_j),m}(t_{j+1} - t_j) q_{m, D}
\end{equation}
The sum is taken over all possible states $m$ which can be visited
between $S(t_j)$ and $D$.

\paragraph{Exactly observed transition times}
If the times $(t_{i1}, \ldots, t_{in_i})$ had been the {\em exact}
transition times between the states, with no transitions between the
observation times, then the contributions would be of the form

\begin{equation}
  \label{eq:multi:lik:exact}
  L_{i, j} =  \exp(q_{S(t_j)S(t_{j})}(t_{j+1} - t_j)) q_{S(t_j)S(t_{j+1})}
\end{equation}
since the state is assumed to be $S(t_j)$ throughout the interval
between $t_j$ and $t_{j+1}$ with a known transition to state
$S(t_{j+1})$ at $t_{j+1}$.  \Rpackage{msm} is restricted to Markov
models, but much richer models are possible for this type of data. For
example, Putter \etal \cite{putter:mstate} discussed the
\Rpackage{mstate} software for semi-parametric multi-state models with
non-parametric baseline hazards and Cox regression.  The Markov
assumption is restrictive but necessary in general to compute a
likelihood for intermittently-observed processes.

\paragraph{Censored states}
A censored quantity is one whose exact value is unknown, but known to
be in a certain interval.  For example, in survival analysis, a death
time is \emph{right-censored} if the study ends and the patient is
still alive, since the death time is known to be greater than the end
time.  In multi-state models for intermittently-observed processes,
the times of changes of state are usually \emph{interval censored},
known to be within bounded intervals.  This leads to a likelihood
based on equation \ref{eq:multi:lik:contrib}.

In some circumstances, \emph{states} may be censored as well as
\emph{event times}.  For example, at the end of some chronic disease
studies, patients are known to be alive but in an \emph{unknown
  state}.  For such a censored observation $S(t_{j+1})$, known only to
be a state in the set $C$, the equivalent contribution to the
likelihood is
\begin{equation}
  \label{eq:multi:lik:deathcens}
  L_{i, j} =  \sum_{m \in C} p_{S(t_j),m}(t_{j+1} - t_j)
\end{equation}
Note that this special likelihood is not needed if the state is known
at the end of the study.  In this case,
likelihood \ref{eq:multi:lik:contrib} applies.  Although the
\emph{survival time} is censored, the \emph{state} at the end of the
study is not censored.

More generally, suppose every observation from a particular individual
is censored.  Observations $1, 2, \ldots n_i$ are known only to be in
the sets $C_1, C_2, \ldots, C_{n_i}$ respectively. The likelihood for
this individual is a sum of the likelihoods of all possible paths
through the unobserved states.
\begin{equation}
  \label{eq:multi:lik:cens}
  L_i = \sum_{s_{n_i} \in C_{n_i}} \ldots \sum_{s_2 \in C_2} \sum_{s_1 \in C_1} p_{s_1 s_2}(t_2 - t_1) p_{s_2 s_3} (t_3 - t_2) \ldots p_{s_{n_i-1} s_{n_i}} (t_{n_i} - t_{n_i-1})
\end{equation}
Suppose the states comprising the set $C_j$ are $c^{(j)}_1, \ldots,
c^{(j)}_{m_j}$. This likelihood can also be written as a matrix
product, say,
\begin{equation}
  \label{eq:multi:lik:cens:matrix}
  L_i = \mathbf{1}^T P^{1,2} P^{2,3} \ldots P^{n_i-1, n_i} \mathbf{1}
\end{equation}
where $P^{j-1, j}$ is a $m_{j-1} \times m_j$ matrix with $(r,s)$ entry
$p_{c^{(j-1)}_r c^{(j)}_s}(t_j - t_{j-1})$, and $\mathbf{1}$ is the
vector of ones.

The \Rpackage{msm} package allows multi-state models to be fitted to
data from processes with arbitrary observation times (panel data), exactly-observed
transition times, exact death times and censored states, or a mixture
of these schemes.


\subsection{Covariates}
\label{sec:multi:covariates}

The relation of constant or time-varying characteristics of
individuals to their transition rates is often of interest in a
multi-state model.  Explanatory variables for a particular transition
intensity can be investigated by modelling the intensity as a function
of these variables.  Marshall and Jones \cite{retino2} described a
form of a {\em proportional hazards} model, where the transition
intensity matrix elements $q_{rs}$ which are of interest can be
replaced by
\[
q_{rs}(z(t)) = q_{rs}^{(0)} \exp(\beta_{rs}^T z(t))
\]
The new $Q$ is then used to determine the likelihood. If the
covariates $z(t)$ are time dependent, the contributions to the
likelihood of the form $p_{rs} (t - u)$ are replaced by
\[
p_{rs}(t - u, z(u))
\]
although this requires that the value of the covariate is known at
every observation time $u$. Sometimes covariates are observed at
different times to the main response, for example recurrent disease
events or other biological markers. In some of these cases it could be
assumed that the covariate is a step function which remains constant
between its observation times.  If the main response (the state of the
Markov process) is not observed at the times when the covariate
changes, it could be considered as a "censored" state (as in
Section \ref{sec:multi:likelihood}).

The \Rpackage{msm} package allows individual-specific or time
dependent covariates to be fitted to transition intensities.  In order
to calculate transition probabilities $P(t)$ on which the likelihood
depends, time-dependent covariates are assumed to be
piecewise-constant.  Models whose intensities change with time are
called \emph{time-inhomogeneous}. An important special case handled by
\Rpackage{msm} is the model in which intensities change at a series of
times common to each individual.

Marshall and Jones \cite{retino2} described likelihood ratio and Wald
tests for covariate selection and testing hypotheses, for example
whether the effect of a covariate is the same for all forward
transitions in a disease progression model, or whether the effect on
backward transitions is equal to minus the effect on forward
transitions.





\subsection{Hidden Markov models}
\label{sec:hmm}


In a {\em hidden Markov model} (HMM) the states of the Markov chain
are not observed. The observed data are governed by some probability
distribution (the \emph{emission} distribution) conditionally on the
unobserved state.  The evolution of the underlying Markov chain is
governed by a transition intensity matrix $Q$ as before.
(Figure \ref{fig:multi:hidden}).  Hidden Markov models are mixture
models, where observations are generated from a certain number of
unknown distributions.  However the distribution changes through time
according to states of a hidden Markov chain.  This class of model is
commonly used in areas such as speech and signal processing
\cite{juang:rabiner} and the analysis of biological sequence data
\cite{biolog:seq}. In engineering and biological sequencing
applications, the Markov process usually evolves over an
equally-spaced, discrete `time' space.  Therefore most of the theory
of HMM estimation was developed for discrete-time models.

HMMs have less frequently been used in medicine, where continuous time
processes are often more suitable.  A disease process evolves in
continuous time, and patients are often monitored at irregular and
differing intervals.  These models are suitable for estimating
population quantities for chronic diseases which have a natural staged
interpretation, but which can only be diagnosed by an error-prone
marker.  The \Rpackage{msm} package can fit continuous-time hidden
Markov models with a variety of emission distributions.


\begin{figure}[htbp]
  \begin{center}
    \scalebox{0.6}{\rotatebox{270}{\includegraphics{figures/hidden}}}
    \caption{A hidden Markov model in continuous time. Observed states
      are generated conditionally on an underlying Markov process. }
    \label{fig:multi:hidden}
  \end{center}
\end{figure}


\subsubsection{Misclassification models}

An example of a hidden Markov model is a multi-state model with
misclassification.  Here the observed data are states, assumed to be
misclassifications of the true, underlying states.

For example, consider a disease progression model with at least a
disease-free and a disease state. When screening for the presence of
the disease, the screening process can sometimes be subject to error.
Then the Markov disease process $S_i(t)$ for individual $i$ is not
observed directly, but through realisations $O_i(t)$.  The quality of
a diagnostic test is often measured by the probabilities that the true
and observed states are equal, $Pr(O_i(t) = r | S_i(t) = r)$. Where
$r$ represents a `positive' disease state, this is the {\em
  sensitivity}, or the probability that a true positive is detected by
the test.  Where $r$ represents a `negative' or disease-free state,
this represents the {\em specificity}, or the probability that, given
the condition of interest is absent, the test produces a negative
result.

As an extension to the simple multi-state model described in
section \ref{sec:multistate}, the \Rpackage{msm} package can fit a
general multi-state model with misclassification.  For patient $i$,
observation time $t_{ij}$, observed states $O_{ij}$ are generated
conditionally on true states $S_{ij}$ according to a {\em
  misclassification matrix} $E$. This is a $n \times n$ matrix, whose
$(r,s)$ entry is
\begin{equation}
  \label{eq:misc}
  e_{rs} = Pr(O(t_{ij}) = s | S(t_{ij}) = r),
\end{equation}
which we first assume to be independent of time $t$. Analogously to
the entries of $Q$, some of the $e_{rs}$ may be fixed to reflect
knowledge of the diagnosis process. For example, the probability of
misclassification may be negligibly small for non-adjacent states of
disease.  Thus the progression through underlying states is governed
by the transition intensity matrix $Q$, while the observation process
of the underlying states is governed by the misclassification matrix
$E$.

To investigate explanatory variables $w(t)$ for the probability $e_{rs}$ of
misclassification as state $s$ given underlying state $r$, a
multinomial logistic regression model can be used:
\begin{equation}
  \label{eq:misccovs}
  \log \frac{e_{rs}(t)}{e_{rs_0}(t)}  =   \gamma_{rs}^T w(t).
\end{equation}
where $s_0$ is some baseline state, usually chosen as the underlying
state, or the state with the highest probability (for numerical
stability).

\subsubsection{General hidden Markov model}
\label{sec:hmm:general}

Consider now a general hidden Markov model in continuous time.  The
true state of the model $S_{ij}$ evolves as an unobserved Markov
process.  Observed data $y_{ij}$ are generated conditionally true
states $S_{ij} = 1, 2, \ldots, n$ according to a set of distributions
$f_1(y | \theta_1, \gamma_1)$, $f_2(y | \theta_2, \gamma_2)$,
$\ldots$, $f_n(y | \theta_n, \gamma_n)$, respectively.  $\theta_r$ is
a vector of parameters for the state $r$ distribution.  One or more of
these parameters may depend on explanatory variables through a
link-transformed linear model with coefficients $\gamma_r$.



\subsubsection{Likelihood for general hidden Markov models}

A type of EM algorithm known as the {\em Baum-Welch} or {\em
  forward-backward} algorithm \cite{baum:petrie66, baum:petrie70}, is
commonly used for hidden Markov model estimation in discrete-time
applications.  See, for example, Durbin \etal
\cite{biolog:seq}, Albert \cite{albert99}.  A generalisation of this
algorithm to continuous time was described by Bureau \etal
\cite{bureau:hughes:shiboski:00}.

The \Rpackage{msm} package uses a direct method of calculating
likelihoods in discrete or continuous time based on matrix products.
This type of method has been described by Macdonald and Zucchini
\cite[pp.  77--79]{macdonald:zucchini}, Lindsey
\cite[p.73]{lindsey:rm} and Guttorp \cite{guttorp}.  Satten and
Longini \cite{sattlong} used this method to calculate likelihoods for
a hidden Markov model in continuous time with observations of a
continuous marker generated conditionally on underlying discrete
states.

Patient $i$'s contribution to the likelihood is
\begin{eqnarray}
  \label{eq:multi:hiddencontrib}
  L_i     & = & Pr(y_{i1}, \ldots, y_{in_i})\\
  & = & \sum Pr(y_{i1}, \ldots, y_{in_i} | S_{i1}, \ldots, S_{in_i})
  Pr(S_{i1}, \ldots, S_{in_i}) \nonumber
\end{eqnarray}
where the sum is taken over all possible paths of underlying states
$S_{i1}, \ldots, S_{in_i}$.  Assume that the observed states are
conditionally independent given the values of the underlying states.
Also assume the Markov property, $Pr(S_{ij}|S_{i,j-1}, \ldots, S_{i1})
= Pr(S_{ij}|S_{i,j-1})$.  Then the contribution $L_i$ can be written
as a product of matrices, as follows. To derive this matrix product,
decompose the overall sum in equation \ref{eq:multi:hiddencontrib}
into sums over each underlying state. The sum is accumulated over the
unknown first state, the unknown second state, and so on until the
unknown final state:
\begin{eqnarray}
  \label{eq:multi:hiddenlik}
  L_i & = & \sum_{S_{i1}} Pr(y_{i1}|S_{i1})Pr(S_{i1}) \sum_{S_{i2}} Pr(y_{i2}|S_{i2})Pr(S_{i2}|S_{i1}) \sum_{S_{i3}} Pr(y_{i3}|S_{i3}) Pr(S_{i3}|S_{i2})
  \nonumber \\
  &   & \ldots \sum_{S_{in_i}} Pr(y_{in_i}|S_{in_i})
  Pr(S_{in_i}|S_{in_{i-1}})
\end{eqnarray}
where $Pr(y_{ij}|S_{ij})$ is the emission probability density.  For
misclassification models, this is the misclassification probability
$e_{S_{ij} O_{ij}}$.  For general hidden Markov models, this is the
probability density
$f_{S_{ij}}(y_{ij}|\theta_{S_{ij}},\gamma_{S_{ij}})$.
$Pr(S_{i,j+1}|S_{ij})$ is the $(S_{ij}, S_{i,j+1})$ entry of the
Markov chain transition matrix $P(t)$ evaluated at $t = t_{i,j+1} -
t_{ij}$.  Let $f$ be the vector with $r$ element the product of the
initial state occupation probability $Pr(S_{i1}=r)$ and $Pr(y_{i1}|
r)$, and let $\mathbf 1$ be a column vector consisting of ones. For $j
= 2, \ldots, n_i$ let $T_{ij}$ be the $R \times R$ matrix (where $R$
is the number of states) with $(r,s)$ entry
\[
Pr(y_{ij}| s) p_{rs} (t_{ij} - t_{i,j-1})
\]
Then subject $i$'s likelihood contribution is
\begin{equation}
  L_i =  f T_{i2} T_{i3}, \ldots T_{in_i} \mathbf 1
  \label{eq:multi:hidden:matprod}
\end{equation}

If $S(t_{j}) = D$ is an absorbing state such as death, measured
without error, whose entry time is known exactly, then the
contribution to the likelihood is summed over the unknown state at the
previous instant before death.  The $(r,s)$ entry of $T_{ij}$ is then
\[
p_{rs}(t_{j} - t_{j-1}) q_{s, D}
\]
Section \ref{sec:fitting:hmm:misc} describes how to fit multi-state
models with misclassification using the \Rpackage{msm} package, and
Section \ref{sec:fitting:hmm:general} describes how to apply general
hidden Markov models.


\subsubsection{Example of a general hidden Markov model}
\label{sec:hmm:example:fev}

Jackson and Sharples \cite{jackson:sharples:2002} described a model
for FEV$_1$ (forced expiratory volume in 1 second) in recipients of
lung transplants.  These patients were at risk of BOS (bronchiolitis
obliterans syndrome), a progressive, chronic deterioration in lung
function.  In this example, BOS was modelled as a discrete, staged
process, a model of the form illustrated in Figure \ref{fig:disease},
with 4 states.  State 1 represents absence of BOS. State 1 BOS is
roughly defined as a sustained drop below 80\% below baseline FEV$_1$,
while state 2 BOS is a sustained drop below 65\% baseline.  FEV$_1$ is
measured as a percentage of a baseline value for each individual,
determined in the first six months after transplant, and assumed to be
100\% baseline at six months.

As FEV$_1$ is subject to high short-term variability due to acute
events and natural fluctuations, the exact BOS state at each
observation time is difficult to determine.  Therefore, a hidden
Markov model for FEV$_1$, conditionally on underlying BOS states, was
used to model the natural history of the disease.  Discrete states are
appropriate as onset is often sudden.


\paragraph{Model 1}
Jackson \cite{my:phd} considered models for these data where
FEV$_1$ were Normally distributed, with an unknown mean and variance
conditionally each state (\ref{eq:fev:normal}).  This model seeks the
most likely location for the within-state FEV$_1$ means.

\begin{equation}
  \label{eq:fev:normal}
  y_{ij} | \{ S_{ij} = k\}  \sim N(\mu_k + \beta x_{ij}, \sigma^2_k)
\end{equation}


\paragraph{Model 2}
Jackson and Sharples \cite{jackson:sharples:2002} used a more complex
two-level model for FEV$_1$ measurements. Level
1 (\ref{eq:fev:level1}) represents the short-term fluctuation error of
the marker around its underlying continuous value $y^{hid}_{ij}$.
Level 2 (\ref{eq:fev:level2}) represents the distribution of
$y^{hid}_{ij}$ conditionally on each underlying state, as follows.
\begin{equation}
  \label{eq:fev:level1}
  y_{ij} | y^{hid}_{ij} \qquad \sim  N ( y^{hid}_{ij} + \beta x_{ij} ,
  \sigma^2_\epsilon)
\end{equation}
\begin{equation}
  \label{eq:fev:level2}
  y^{hid}_{ij} | S_{ij} \quad \sim \quad
  \left\{
    \begin{array}{cll}
      \mbox{State}& \mbox{Three state model}               & \mbox{Four state model} \\
      S_{ij} = 0  & N(\mu_0, \sigma^2_0)I_{[80, \infty)} & N(\mu_0, \sigma^2_0)I_{[80, \infty)} \\
      S_{ij} = 1  & N(\mu_1, \sigma^2_1)I_{(0, 80)}      & Uniform(65, 80)                        \\
      S_{ij} = 2  & \mbox{(death)}                         & N(\mu_2, \sigma^2_2)I_{(0, 65)}      \\
      S_{ij} = 3  &                                        & \mbox{(death)}
    \end{array}
  \right .
\end{equation}

Integrating over $y^{hid}_{ij}$ gives an explicit distribution for
$y_{ij}$ conditionally on each underlying state (given in
Section \ref{sec:fitting:hmm:general}, Table \ref{tab:hmm:dists}).
Similar distributions were originally applied by Satten and
Longini \cite{sattlong} to modelling the progression through discrete,
unobserved HIV disease states using continuous CD4 cell counts.  The
\Rpackage{msm} package includes density, quantile, cumulative density
and random number generation functions for these distributions.

In both models 1 and 2, the term $\beta x_{ij}$ models the short-term
fluctuation of the marker in terms of acute events. $x_{ij}$ is an
indicator for the occurrence of an acute rejection or infection
episode within 14 days of the observation of FEV$_1$.

Section \ref{sec:fitting:hmm:general} describes how these and more
general hidden Markov models can be fitted with the \Rpackage{msm}
package.



\clearpage

\section{Fitting multi-state models with {\tt msm}}

<<echo=FALSE>>=
options(width = 60)
@

\Rpackage{msm} is a package of functions for multi-state modelling using
the R statistical software.  The \Rfunction{msm} function itself
implements maximum-likelihood estimation for general multi-state
Markov or hidden Markov models in continuous time. We illustrate
its use with a set of data from monitoring heart transplant patients.
Throughout this section ``\textsl{\texttt{>}}'' indicates the R
command prompt, \textsl{\texttt{slanted typewriter}} text indicates R
commands, and \texttt{typewriter} text R output.

\subsection{Installing \tt{msm}}
\label{sec:installing}

The easiest way to install the \Rpackage{msm} package on a computer
connected to the Internet is to run the R command:

\begin{Scode}
  install.packages("msm")
\end{Scode}

This downloads \Rpackage{msm} from the CRAN archive of contributed R
packages (\texttt{cran.r-project.org} or one of its mirrors) and
installs it to the default R system library.  To install to a
different location, for example if you are a normal user with no
administrative privileges, create a directory in which R packages are
to be stored, say, \texttt{/your/library/dir}, and run

\begin{Scode}
  install.packages("msm", lib='/your/library/dir')
\end{Scode}

After \Rpackage{msm} has been installed, its functions can be made
visible in an R session by
<<>>=
library(msm)
@
or, if it has been installed into a non-default library,

\begin{Scode}
  library(msm, lib.loc='/your/library/dir')
\end{Scode}


\subsection{Getting the data in}
\label{sec:datain}

The data are specified as a series of observations, grouped by
patient. At minimum there should be a data frame with variables
indicating
\begin{itemize}
\item the time of the observation,
\item the observed state of the process.
\end{itemize}
If the data do not also contain
\begin{itemize}
\item the subject identification number,
\end{itemize}
then all the observations are assumed to be from the same subject.
The subject ID does not need to be numeric, but data must be grouped
by subject, and observations must be ordered by time within subjects.
If the model includes variables with missing values, then the corresponding
observations  are omitted by \Rfunction{msm} with a warning.  If you have missing data,
as in any statistical model, it is recommended to ensure these do not
result in biases.

An example data set, taken from monitoring a set of heart transplant
recipients, is provided with \Rpackage{msm}.  (Note: since \Rpackage{msm}
version 1.3, the command \Rfunction{data(cav)} is no longer needed to
load the data --- it is now ``lazy-loaded'' when required). Sharples
\etal \cite{my:cav} studied the progression of coronary allograft
vasculopathy (CAV), a post-transplant deterioration of the arterial
walls, using these data.  Risk factors and the accuracy of the
screening test were investigated using multi-state Markov and hidden
Markov models.

The first three patient histories are shown below. There are 622
patients in all.  \Robject{PTNUM} is the subject identifier.
Approximately each year after transplant, each patient has an
angiogram, at which CAV can be diagnosed.  The result of the test is
in the variable \Robject{state}, with possible values 1, 2, 3
representing CAV-free, mild CAV and moderate or severe CAV
respectively.  A value of 4 is recorded at the date of death.
\Robject{years} gives the time of the test in years since the heart
transplant. Other variables include \Robject{age} (age at screen),
\Robject{dage} (donor age), \Robject{sex} (0=male, 1=female),
\Robject{pdiag} (primary diagnosis, or reason for transplant - IHD
represents ischaemic heart disease, IDC represents idiopathic dilated
cardiomyopathy), \Robject{cumrej} (cumulative number of rejection
episodes), and \Robject{firstobs}, an indicator which is 1 when the
observation corresponds to the patient's transplant (the first
observation), and 0 when the observation corresponds to a later
angiogram.

<<>>=
cav[1:21,]
@

A useful way to summarise multi-state data is as a frequency table of
pairs of consecutive states.  This counts over all individuals, for
each state $r$ and $s$, the number of times an individual had an
observation of state $r$ followed by an observation of state $s$. The
function \Rfunction{statetable.msm} can be used to produce such a table,
as follows,

<<>>=
statetable.msm(state, PTNUM, data=cav)
@
Thus there were 148 CAV-free deaths, 48 deaths from state 2, and
55 deaths from state 3.  On only four occasions was there an
observation of severe CAV followed by an observation of no CAV.


\subsection{Specifying a model}
\label{sec:specifying:model}

We now specify the multi-state model to be fitted to the data.  A
model is governed by a transition intensity matrix $Q$. For the heart
transplant example, there are four possible states through which the
patient can move, corresponding to CAV-free, mild/moderate CAV, severe
CAV and death.  We assume that the patient can advance or recover from
consecutive states while alive, and die from any state. Thus the model
is illustrated by Figure \ref{fig:disease} with four states, and we
have

\[
Q = \left(
  \begin{array}{llll}
    -(q_{12} + q_{14}) & q_{12} &  0     & q_{14}\\
    q_{21} & -(q_{21}+q_{23}+q_{24}) & q_{23} & q_{24}\\
      0    & q_{32} & -(q_{32}+q_{34}) & q_{34}\\
      0    &   0    &   0    &   0   \\
  \end{array}
\right )
\]

It is important to remember that this defines which
\emph{instantaneous} transitions can occur in the Markov process, and
that the data are \emph{snapshots} of the process (see
section \ref{sec:arbitr-observ-times}).  Although there were 44
occasions on which a patient was observed in state 1 followed by state
3, the underlying model specifies that the patient must have passed
through state 2 in between.  If your data represent the exact and
complete transition times of the process, then you must specify
\Rfunarg{exacttimes=TRUE} or \Rfunarg{obstype=2} in the call to
\Rfunction{msm}.

To tell \Rfunction{msm} what the allowed transitions of our model are,
we define a matrix of the same size as $Q$, containing zeroes in the
positions where the entries of $Q$ are zero.  All other positions
contain an initial value for the corresponding transition intensity.
The diagonal entries supplied in this matrix do not matter, as the
diagonal entries of $Q$ are defined as minus the sum of all the other
entries in the row.  This matrix will eventually be used as the
\Rfunarg{qmatrix} argument to the \Rfunction{msm} function. For
example,

<<>>=
twoway4.q  <-  rbind ( c(0, 0.25, 0, 0.25),
                       c(0.166, 0, 0.166, 0.166),
                       c(0, 0.25, 0, 0.25),
                       c(0, 0, 0, 0) )
@

Fitting the model is a process of finding values of the seven unknown
transition intensities: $q_{12}$, $q_{14}$, $q_{21}$, $q_{23}$,
$q_{24}$, $q_{32}$, $q_{34}$, which maximise the likelihood.

\subsection{Specifying initial values}
\label{sec:inits}

The likelihood is maximised by numerical methods, which need a set of
initial values to start the search for the maximum.  For reassurance
that the true maximum likelihood estimates have been found, models
should be run repeatedly starting from different initial
values. However a sensible choice of initial values can be important
for unstable models with flat or multi-modal likelihoods.  For
example, the transition rates for a model with misclassification could
be initialised at the corresponding estimates for an approximating
model without misclassification. Initial values for a model without
misclassification could be set by supposing that transitions between
states take place only at the observation times.  If we observe
$n_{rs}$ transitions from state $r$ to state $s$, and a total of $n_r$
transitions from state $r$, then $q_{rs} / q_{rr}$ can be estimated by
$n_{rs} / n_r$. Then, given a total of $T_r$ years spent in state $r$,
the mean sojourn time $1 / q_{rr}$ can be estimated as $T_r / n_r$.
Thus, $n_{rs} / T_r$ is a crude estimate of $q_{rs}$. The \Rpackage{msm}
package provides a function \Rfunction{crudeinits.msm} for calculating
initial values in this way (for non-hidden Markov models).

<<>>=
twoway4.crude.q  <- crudeinits.msm(state ~ years, PTNUM, data=cav, qmatrix=twoway4.q)
@

However, if there are are many changes of state in between the
observation times, then this crude approach may fail to give sensible
initial values.  For the heart transplant example we could also guess
that the mean period in each state before moving to the next is about
2 years, and there is an equal probability of progression, recovery or
death.  This gives $q_{rr} = - 0.5$ for $r = 1, 2, 3$, and $q_{12} =
q_{14} = 0.25$, $q_{21} = q_{23} = q_{24} = 0.166$, $q_{32} = q_{34} =
0.25$, and the initial value matrix \Robject{twoway4.q} shown above,
which we now use to fit the model.

%% TODO explain about gen.inits=TRUE here

\subsection{Running \Rfunction{msm}}
\label{sec:running}

To fit the model, call the \Rfunction{msm} function with the appropriate
arguments.  For our running example, we have defined a data set
\Robject{cav}, a matrix \Robject{twoway4.q} indicating the allowed
transitions, and initial values. We are ready to run \Rfunction{msm}.

\paragraph{Model 1: simple bidirectional model}

\end{document}
